{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%pip install --quiet bitsandbytes==0.45.0 transformers==4.47.1 accelerate==1.2.1 sentencepiece==0.2.0 optimum==1.23.3 auto-gptq==0.7.1 torchmetrics\n",
        "\n",
        "import gc\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import transformers\n",
        "import bitsandbytes as bnb\n",
        "import subprocess\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datasets import load_dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm.auto import tqdm, trange\n",
        "from IPython.display import clear_output\n",
        "from random import sample\n",
        "from tqdm import tqdm\n",
        "from torchmetrics.functional import accuracy\n",
        "from torch.optim import AdamW\n",
        "from peft import PromptTuningConfig, PromptTuningInit, get_peft_model, LoraConfig, TaskType\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, BitsAndBytesConfig\n",
        "\n",
        "sns.set_theme()\n",
        "\n",
        "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "EYYmyrtAYSPW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea5dc7ff-9dd0-4ad9-8e73-a75c55510f05"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m336.4/336.4 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m424.1/424.1 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.5/23.5 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m931.6/931.6 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m53.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.4/485.4 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m65.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:bitsandbytes.cextension:The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import re\n",
        "import ast\n",
        "from typing import List, Dict, Any\n",
        "\n",
        "def parse_all_data(file_path: str) -> List[Dict[str, Any]]:\n",
        "    \"\"\"Парсинг всех данных без учета времени ответа\"\"\"\n",
        "    return _parse_data(file_path, include_time=False)\n",
        "\n",
        "def parse_data_with_time(file_path: str) -> List[Dict[str, Any]]:\n",
        "    \"\"\"Парсинг данных с сохранением времени ответа\"\"\"\n",
        "    return _parse_data(file_path, include_time=True)\n",
        "\n",
        "def _parse_data(file_path: str, include_time: bool) -> List[Dict[str, Any]]:\n",
        "    \"\"\"Базовая функция парсинга\"\"\"\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    result = []\n",
        "    for item in data:\n",
        "        parsed = {\n",
        "            'selected_role': item['Выбранная роль'],\n",
        "            'campus': item['Кампус'],\n",
        "            'education_level': item['Уровень образования'],\n",
        "            'question_category': item['Категория вопроса'],\n",
        "            'user_question': _clean_text(item['Вопрос пользователя']),\n",
        "            'user_filters': item['user_filters'],\n",
        "            'question_filters': item['question_filters'],\n",
        "            'saiga_answer': _clean_text(item['Saiga']),\n",
        "            'giga_answer': _clean_text(item['Giga']),\n",
        "            'winner': item['Кто лучше?'],\n",
        "            'comment': item['Комментарий'],\n",
        "            'contexts': _parse_contexts(item['Ресурсы для ответа'])\n",
        "        }\n",
        "\n",
        "        if item.get('Уточненный вопрос пользователя'):\n",
        "            parsed.update({\n",
        "                'refined_question': _clean_text(item['Уточненный вопрос пользователя']),\n",
        "                'refined_answer': _clean_text(item['Ответ AI (уточнение)']),\n",
        "                'refined_contexts': _parse_contexts(item['Ресурсы для ответа (уточнение)'] or '')\n",
        "            })\n",
        "\n",
        "        if include_time:\n",
        "            parsed.update({\n",
        "                'response_time': item['Время ответа модели (сек)'],\n",
        "                'refined_response_time': item.get('Время ответа модели на уточненный вопрос (сек)')\n",
        "            })\n",
        "\n",
        "        result.append(parsed)\n",
        "\n",
        "    return result\n",
        "\n",
        "def _parse_contexts(resources: str) -> List[Dict[str, Any]]:\n",
        "    \"\"\"Парсинг контекстов с использованием вашей функции\"\"\"\n",
        "    contexts = []\n",
        "    pattern = re.compile(r\"Document\\(page_content='(.*?)', metadata=({.*?})\\)\", re.DOTALL)\n",
        "\n",
        "    for match in re.finditer(pattern, resources):\n",
        "        content, metadata_str = match.groups()\n",
        "        try:\n",
        "            metadata = ast.literal_eval(metadata_str)\n",
        "            tags = _extract_tags(metadata)\n",
        "\n",
        "            contexts.append({\n",
        "                'text': _clean_text(content),\n",
        "                'metadata': {\n",
        "                    'source': metadata.get('source'),\n",
        "                    'file_name': metadata.get('file_name'),\n",
        "                    'url': metadata.get('url')\n",
        "                },\n",
        "                'tags': tags\n",
        "            })\n",
        "        except Exception as e:\n",
        "            print(f\"Контекст не распарсился: {e}\")\n",
        "\n",
        "    return contexts\n",
        "\n",
        "def _extract_tags(metadata: Dict) -> Dict[str, List[str]]:\n",
        "    \"\"\"Извлечение тегов в отдельные категории\"\"\"\n",
        "    return {\n",
        "        'topic_tags': [v for k,v in metadata.items() if k.startswith('topic_tag_') and v],\n",
        "        'user_tags': [v for k,v in metadata.items() if k.startswith('user_tag_') and v]\n",
        "    }\n",
        "\n",
        "def _clean_text(text: str) -> str:\n",
        "    \"\"\"Очистка текста\"\"\"\n",
        "    if not text: return ''\n",
        "    return re.sub(r'\\\\[nrt]|[\\n\\r\\t]+|\\s+', ' ', text).strip()"
      ],
      "metadata": {
        "id": "8gVwLsJOb_Kl"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QyvsEq2IeG8Z",
        "outputId": "a5ae3261-3925-4675-8168-d209c5edc931"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.3.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (1.26.4)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.10.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (24.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.17.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.11.13)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.18.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
            "Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: evaluate\n",
            "Successfully installed evaluate-0.4.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kr3ThJrffGT",
        "outputId": "0e7622c0-7d5c-4d73-ec2e-9da6e0567e7f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rouge_score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge_score) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.26.4)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (4.67.1)\n",
            "Building wheels for collected packages: rouge_score\n",
            "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=db04229f541d4a575505923d0f809ea701c23b5252e8a1631eefc69e28f6d44f\n",
            "  Stored in directory: /root/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\n",
            "Successfully built rouge_score\n",
            "Installing collected packages: rouge_score\n",
            "Successfully installed rouge_score-0.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sacrebleu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCrP_DsNfqbp",
        "outputId": "2c4f8167-c133-43d2-9645-795999115915"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/51.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting portalocker (from sacrebleu)\n",
            "  Downloading portalocker-3.1.1-py3-none-any.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (2024.11.6)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (1.26.4)\n",
            "Collecting colorama (from sacrebleu)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (5.3.1)\n",
            "Downloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading portalocker-3.1.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: portalocker, colorama, sacrebleu\n",
            "Successfully installed colorama-0.4.6 portalocker-3.1.1 sacrebleu-2.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bert_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldIzhMUcf25e",
        "outputId": "e7734684-e6c1-4794-dd32-5d998f5adca6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bert_score\n",
            "  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from bert_score) (2.5.1+cu124)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from bert_score) (2.2.2)\n",
            "Requirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from bert_score) (4.47.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from bert_score) (1.26.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from bert_score) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.11/dist-packages (from bert_score) (4.67.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from bert_score) (3.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from bert_score) (24.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert_score) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert_score) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert_score) (2025.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.0.0->bert_score) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert_score) (0.28.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert_score) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert_score) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert_score) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert_score) (0.5.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (3.2.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->bert_score) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->bert_score) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->bert_score) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->bert_score) (2025.1.31)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert_score) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.0.0->bert_score) (3.0.2)\n",
            "Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: bert_score\n",
            "Successfully installed bert_score-0.3.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "\n",
        "import evaluate\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "rouge = evaluate.load(\"rouge\")\n",
        "bleu = evaluate.load(\"bleu\")\n",
        "chrf = evaluate.load(\"chrf\")\n",
        "bertscore = evaluate.load(\"bertscore\")\n",
        "\n",
        "\n",
        "def context_recall(ground_truth: str, contexts: List[str])->float:\n",
        "    \"\"\"\n",
        "    Calc rouge btw contexts and ground truth.\n",
        "    Interpretation: ngram match (recall) btw contexts and desired answer.\n",
        "\n",
        "    ROUGE - https://huggingface.co/spaces/evaluate-metric/rouge\n",
        "\n",
        "    return: average rouge for all contexts.\n",
        "    \"\"\"\n",
        "    rs = []\n",
        "    for c in contexts:\n",
        "        rs.append(\n",
        "            rouge.compute(\n",
        "                predictions=[str(c)],\n",
        "                references=[str(ground_truth)],\n",
        "            )[\"rouge2\"]\n",
        "        )\n",
        "\n",
        "    return np.mean(rs)\n",
        "\n",
        "\n",
        "def context_precision(ground_truth: str, contexts: List[str])->float:\n",
        "    \"\"\"\n",
        "    Calc blue btw contexts and ground truth.\n",
        "    Interpretation: ngram match (precision) btw contexts and desired answer.\n",
        "\n",
        "    BLEU - https://aclanthology.org/P02-1040.pdf\n",
        "    max_order - max n-grams to count\n",
        "\n",
        "    return: average bleu (precision2, w/o brevity penalty) for all contexts.\n",
        "    \"\"\"\n",
        "    bs = []\n",
        "    for c in contexts:\n",
        "\n",
        "        try:\n",
        "            bs.append(\n",
        "                bleu.compute(\n",
        "                    predictions=[str(c)],\n",
        "                    references=[str(ground_truth)],\n",
        "                    max_order=2,\n",
        "                )[\"precisions\"][1]\n",
        "            )\n",
        "        except ZeroDivisionError:\n",
        "            bs.append(0)\n",
        "\n",
        "    return np.mean(bs)\n",
        "\n",
        "\n",
        "def answer_correctness_literal(\n",
        "    ground_truth: str,\n",
        "    answer: str,\n",
        "    char_order: int = 6,\n",
        "    word_order: int = 2,\n",
        "    beta: float = 1,\n",
        ")->float:\n",
        "    \"\"\"\n",
        "    Calc chrF btw answer and ground truth.\n",
        "    Interpretation: lingustic match btw answer and desired answer.\n",
        "\n",
        "    chrF - https://aclanthology.org/W15-3049.pdf\n",
        "    char_order - n-gram length for chars, default is 6 (from the article)\n",
        "    word_order - n-gram length for words (chrF++), default is 2 (as it outperforms simple chrF)\n",
        "    beta - recall weight, beta=1 - simple F1-score\n",
        "\n",
        "    return: chrF for answ and gt.\n",
        "    \"\"\"\n",
        "\n",
        "    score = chrf.compute(\n",
        "        predictions=[str(answer)],\n",
        "        references=[str(ground_truth)],\n",
        "        word_order=word_order,\n",
        "        char_order=char_order,\n",
        "        beta=beta,\n",
        "    )[\"score\"]\n",
        "\n",
        "    return score\n",
        "\n",
        "\n",
        "def answer_correctness_neural(\n",
        "    ground_truth: str,\n",
        "    answer: str,\n",
        "    model_type: str = \"cointegrated/rut5-base\",\n",
        ")->float:\n",
        "    \"\"\"\n",
        "    Calc bertscore btw answer and ground truth.\n",
        "    Interpretation: semantic cimilarity btw answer and desired answer.\n",
        "\n",
        "    BertScore - https://arxiv.org/pdf/1904.09675.pdf\n",
        "    model_type - embeds model  (default t5 as the best from my own research and experience)\n",
        "\n",
        "    return: bertscore-f1 for answ and gt.\n",
        "    \"\"\"\n",
        "\n",
        "    score = bertscore.compute(\n",
        "        predictions=[str(answer)],\n",
        "        references=[str(ground_truth)],\n",
        "        batch_size=1,\n",
        "        model_type=model_type,\n",
        "        num_layers=11,\n",
        "    )[\"f1\"]\n",
        "\n",
        "    return score\n",
        "\n",
        "\n",
        "class ValidatorSimple:\n",
        "    \"\"\"\n",
        "    Расчет простых метрик качества для заданного датасета.\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        neural: bool = False,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        param neural: есть гпу или нет. По дефолту ее нет(\n",
        "        \"\"\"\n",
        "        self.neural = neural\n",
        "\n",
        "    def score_sample(\n",
        "        self,\n",
        "        answer: str,\n",
        "        ground_truth: str,\n",
        "        context: List[str],\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Расчет для конкретного сэмпла в тестовом датасете.\n",
        "        \"\"\"\n",
        "        scores = {}\n",
        "        scores[\"context_recall\"] = [\n",
        "            context_recall(\n",
        "                ground_truth,\n",
        "                context,\n",
        "            )\n",
        "        ]\n",
        "        scores[\"context_precision\"] = [\n",
        "            context_precision(\n",
        "                ground_truth,\n",
        "                context,\n",
        "            )\n",
        "        ]\n",
        "        scores[\"answer_correctness_literal\"] = [\n",
        "            answer_correctness_literal(\n",
        "                ground_truth=ground_truth,\n",
        "                answer=answer,\n",
        "            )\n",
        "        ]\n",
        "        if self.neural:\n",
        "            scores[\"answer_correctness_neural\"] = [\n",
        "                answer_correctness_neural(\n",
        "                    ground_truth=ground_truth,\n",
        "                    answer=answer,\n",
        "                )\n",
        "            ]\n",
        "        return scores\n",
        "\n",
        "    def validate_rag(\n",
        "        self,\n",
        "        test_set: pd.DataFrame,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        param test_set: пандас датасет с нужными полями: answer, ground_truth, context, question\n",
        "        \"\"\"\n",
        "\n",
        "        res = {}\n",
        "        for _, row in tqdm(test_set.iterrows(), \"score_sample\"):\n",
        "            gt = row.ground_truth\n",
        "            answer = row.answer\n",
        "            context = row.contexts\n",
        "            scores = self.score_sample(answer, gt, context)\n",
        "            if not res:\n",
        "                res = scores\n",
        "            else:\n",
        "                for k, v in scores.items():\n",
        "                    res[k].extend(v)\n",
        "        for k, v in res.items():\n",
        "            res[k] = np.mean(res[k])\n",
        "        return res"
      ],
      "metadata": {
        "id": "ket0hdC2csS_"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data_v1 = parse_all_data('val_set.json')\n",
        "\n",
        "data_v2 = parse_data_with_time('val_set.json')\n",
        "\n",
        "with open('parsed_tuning.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(data_v1, f, ensure_ascii=False)\n",
        "\n",
        "with open('parsed_dash.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(data_v2, f, ensure_ascii=False)"
      ],
      "metadata": {
        "id": "ff40xXM3gWBa"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open('parsed_tuning.json', 'r', encoding='utf-8') as f:\n",
        "    training_data = json.load(f)"
      ],
      "metadata": {
        "id": "cNdFIL5HgtmT"
      },
      "execution_count": 20,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}